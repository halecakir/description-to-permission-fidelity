{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "\n",
    "from utils.io_utils import IOUtils\n",
    "from utils.nlp_utils import NLPUtils\n",
    "\n",
    "SAVED_PARAMETERS_DIR_NAME = os.path.join(os.path.abspath(''), \"../../../data/saved_parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = os.path.join(SAVED_PARAMETERS_DIR_NAME, \"embeddings.pickle\")\n",
    "embedding_file_type = \"pickle\"\n",
    "saved_vocab_file = os.path.join(SAVED_PARAMETERS_DIR_NAME, \"vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ext_embeddings, ext_emb_dim = IOUtils.load_embeddings_file(embedding_file,\n",
    "                                                           embedding_file_type,\n",
    "                                                           lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_normalize(v):\n",
    "    norm = np.sum(v)\n",
    "    return v / norm\n",
    "\n",
    "def l2_normalize(v):\n",
    "    norm = np.sqrt(np.sum(np.square(v)))\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_vocab(file_name):\n",
    "    words = {}\n",
    "    with open(file_name, \"r\") as target:\n",
    "        for idx, line in enumerate(target):\n",
    "            words[line.rstrip()] = idx          \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def dot(v1, v2):\n",
    "    return sum(x*y for x,y in zip(v1,v2))\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    cs = dot(x, y) / (np.sqrt(dot(x, x)) * np.sqrt(dot(y, y)))\n",
    "    return (cs + 1)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_vocabs = read_vocab(saved_vocab_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y):   \n",
    "    return np.sqrt(np.sum((x - y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"google\"\n",
    "destination = \"search\"\n",
    "print(cosine_similarity(ext_embeddings[source], ext_embeddings[destination])) # 0.5814327001571655\n",
    "print(euclidean_distance(ext_embeddings[source], ext_embeddings[destination])) # 1.73346\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"google\"\n",
    "destination = \"work\"\n",
    "print(cosine_similarity( ext_embeddings[source], ext_embeddings[destination])) # 0.5681213513016701\n",
    "print(euclidean_distance(ext_embeddings[source], ext_embeddings[destination])) # 1.49079\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = [\"google\"]\n",
    "destination = [\"search\", \"efficient\"]\n",
    "s = np.mean([ext_embeddings[i] for i in source], axis=0)\n",
    "d = np.mean([ext_embeddings[i] for i in destination], axis=0)\n",
    "print(cosine_similarity(s, d)) # 0.6448605805635452\n",
    "print(euclidean_distance(s, d)) # 1.01008\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_distribution(data):\n",
    "    from matplotlib import pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set_style('darkgrid')\n",
    "    sns.distplot(data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def find_similarities(words, model):\n",
    "    sims = {\"source\" : {}, \"destionation\" : {}, \"similarity\" : {}}\n",
    "    index = 0\n",
    "    for word in words:\n",
    "        vec1 = None\n",
    "        if \"_\" in word:\n",
    "            splitted = word.split(\"_\")\n",
    "            vec1 = model[splitted[0]] * model[splitted[1]]\n",
    "        else:\n",
    "            vec1 = model[word]\n",
    "        lst = list(model.keys())\n",
    "        random.shuffle(lst)\n",
    "        for idx, key in zip(range(300), lst): \n",
    "            sims[\"source\"][index] = word\n",
    "            sims[\"destionation\"][index] = key\n",
    "            sims[\"similarity\"][index] = cosine_similarity(vec1, model[key]) \n",
    "            index += 1\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def find_most_sim(similarities, top_k):\n",
    "    sorted_x = sorted(similarities.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for index, (key, val) in zip(range(top_k), sorted_x):\n",
    "        print(\"{}. {} - {}\".format(index+1, key, val))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxplot(data):\n",
    "    from matplotlib import pyplot as plt\n",
    "    import seaborn as sns\n",
    "    ax = sns.boxplot(x=\"day\", data=data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "sims = find_similarities([\"read\",\n",
    "                          \"calendar\",\n",
    "                          \"contacts\", \n",
    "                          \"record\", \n",
    "                          \"audio\", \n",
    "                          \"read_contacts\", \n",
    "                          \"read_calendar\", \n",
    "                          \"record_audio\",\n",
    "                          \"space\",\n",
    "                          \"efficient\",\n",
    "                          \"space_efficient\"], \n",
    "                         ext_embeddings)\n",
    "df = pd.DataFrame.from_dict(sims) \n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "ax = sns.boxplot(x=\"source\", y=\"similarity\", data=df)\n",
    "plt.savefig(\"boxplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set(style=\"whitegrid\")\n",
    "sims = find_similarities([\"read\",\n",
    "                          \"calendar\",\n",
    "                          \"contacts\", \n",
    "                          \"record\", \n",
    "                          \"audio\", \n",
    "                          \"read_contacts\", \n",
    "                          \"read_calendar\", \n",
    "                          \"record_audio\",\n",
    "                          \"space\",\n",
    "                          \"efficient\",\n",
    "                          \"space_efficient\"], \n",
    "                         ext_embeddings)\n",
    "df = pd.DataFrame.from_dict(sims) \n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "ax = sns.boxplot(x=\"source\", y=\"similarity\", data=df)\n",
    "ax = sns.swarmplot(x=\"source\", y=\"similarity\", data=df, color=\".25\")\n",
    "plt.savefig(\"swarmplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.keys():\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(160, 160)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatptığını belirten gurur verter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.savefig(\"tnse.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(ext_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
