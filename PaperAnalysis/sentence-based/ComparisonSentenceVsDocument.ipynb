{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "seed = 10\n",
    "\n",
    "import dynet_config\n",
    "\n",
    "# Declare GPU as the default device type\n",
    "dynet_config.set_gpu()\n",
    "# Set some parameters manualy\n",
    "dynet_config.set(mem=400, random_seed=seed)\n",
    "# Initialize dynet import using above configuration in the current scope\n",
    "import dynet as dy\n",
    "\n",
    "\n",
    "from common import SentenceReport\n",
    "from utils.io_utils import IOUtils\n",
    "from utils.nlp_utils import NLPUtils\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.w2i = None\n",
    "        self.entries = None\n",
    "        self.train_entries = None\n",
    "        self.test_entries = None\n",
    "        self.ext_embedding = None\n",
    "        self.reviews = None\n",
    "        self.predicted_reviews = None\n",
    "\n",
    "    def to(self, device):\n",
    "        if self.entries:\n",
    "            for entry in self.entries:\n",
    "                entry.index_tensor = entry.index_tensor.to(device=device)\n",
    "        if self.reviews:\n",
    "            for doc_id in self.reviews:\n",
    "                for review in self.reviews[doc_id]:\n",
    "                    review.index_tensor = review.index_tensor.to(device=device)\n",
    "        if self.predicted_reviews:\n",
    "            for doc_id in self.predicted_reviews:\n",
    "                for review in self.predicted_reviews[doc_id]:\n",
    "                    review.index_tensor = review.index_tensor.to(device=device)\n",
    "\n",
    "    def load(self, infile):\n",
    "        with open(infile, \"rb\") as target:\n",
    "            self.ext_embeddings, self.entries, self.w2i = pickle.load(target)\n",
    "\n",
    "    def save_data(self, infile):\n",
    "        with open(infile, \"rb\") as target:\n",
    "            self.ext_embeddings, self.entries, self.w2i = pickle.dump(target)\n",
    "\n",
    "    def load_predicted_reviews(self, infile):\n",
    "        with open(infile, \"rb\") as target:\n",
    "            self.predicted_reviews = pickle.load(target)\n",
    "        for app_id in self.predicted_reviews.keys():\n",
    "            self.predicted_reviews[app_id].sort(\n",
    "                key=lambda x: x.prediction_result.item(), reverse=True\n",
    "            )\n",
    "\n",
    "    def load_reviews(self, infile):\n",
    "        with open(infile, \"rb\") as target:\n",
    "            self.reviews = pickle.load(target)\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, data, opt):\n",
    "        self.opt = opt\n",
    "        self.model = dy.ParameterCollection()\n",
    "        self.trainer = dy.MomentumSGDTrainer(self.model)\n",
    "        self.w2i = data.w2i\n",
    "        self.wdims = opt.embedding_size\n",
    "        self.ldims = opt.hidden_size\n",
    "        self.attsize = opt.attention_size\n",
    "\n",
    "        self.ext_embeddings = data.ext_embeddings\n",
    "        # Model Parameters\n",
    "        self.wlookup = self.model.add_lookup_parameters((len(self.w2i), self.wdims))\n",
    "\n",
    "        self.__load_external_embeddings()\n",
    "\n",
    "        if self.opt.encoder_dir == \"single\":\n",
    "            if self.opt.encoder_type == \"lstm\":\n",
    "                self.sentence_rnn = [\n",
    "                    dy.VanillaLSTMBuilder(1, self.wdims, self.ldims, self.model)\n",
    "                ]\n",
    "            elif self.opt.encoder_type == \"gru\":\n",
    "                self.sentence_rnn = [\n",
    "                    dy.GRUBuilder(1, self.wdims, self.ldims, self.model)\n",
    "                ]\n",
    "            self.attention_w = self.model.add_parameters((self.attsize, self.ldims))\n",
    "            self.attention_b = self.model.add_parameters(self.attsize)\n",
    "            self.att_context = self.model.add_parameters(self.attsize)\n",
    "            self.mlp_w = self.model.add_parameters((1, self.ldims + 2 * self.ldims))\n",
    "            self.mlp_b = self.model.add_parameters(1)\n",
    "        elif self.opt.encoder_dir == \"bidirectional\":\n",
    "            if self.opt.encoder_type == \"lstm\":\n",
    "                self.sentence_rnn = [\n",
    "                    dy.VanillaLSTMBuilder(1, self.wdims, self.ldims, self.model),\n",
    "                    dy.VanillaLSTMBuilder(1, self.wdims, self.ldims, self.model),\n",
    "                ]\n",
    "            elif self.opt.encoder_type == \"gru\":\n",
    "                self.sentence_rnn = [\n",
    "                    dy.GRUBuilder(1, self.wdims, self.ldims, self.model),\n",
    "                    dy.GRUBuilder(1, self.wdims, self.ldims, self.model),\n",
    "                ]\n",
    "\n",
    "            self.attention_w = self.model.add_parameters((self.attsize, 2 * self.ldims))\n",
    "            self.attention_b = self.model.add_parameters(self.attsize)\n",
    "            self.att_context = self.model.add_parameters(self.attsize)\n",
    "            self.mlp_w = self.model.add_parameters((1, 2 * self.ldims + 4 * self.ldims))\n",
    "            self.mlp_b = self.model.add_parameters(1)\n",
    "            \n",
    "\n",
    "    def __load_external_embeddings(self):\n",
    "        print(\"Initializing word embeddings by pre-trained vectors\")\n",
    "        count = 0\n",
    "        for word in self.w2i:\n",
    "            if word in self.ext_embeddings:\n",
    "                count += 1\n",
    "                self.wlookup.init_row(self.w2i[word], self.ext_embeddings[word])\n",
    "        print(\n",
    "            \"Vocab size: %d; #words having pretrained vectors: %d\"\n",
    "            % (len(self.w2i), count)\n",
    "        )\n",
    "\n",
    "    def save(self):\n",
    "        self.model.save(self.opt.model_checkpoint)\n",
    "\n",
    "    def load(self):\n",
    "        self.model.populate(self.opt.model_checkpoint)\n",
    "\n",
    "def write_file(filename, string):\n",
    "    with open(filename, \"a\") as target:\n",
    "        target.write(\"{}\\n\".format(string))\n",
    "        target.flush()\n",
    "\n",
    "\n",
    "def encode_sequence(model, seq, rnn_builder):\n",
    "    def predict_sequence(builder, inputs):\n",
    "        s_init = builder.initial_state()\n",
    "        return s_init.transduce(inputs)\n",
    "\n",
    "    if model.opt.encoder_dir == \"bidirectional\":\n",
    "        f_in = [entry for entry in seq]\n",
    "        b_in = [rentry for rentry in reversed(seq)]\n",
    "        forward_sequence = predict_sequence(rnn_builder[0], f_in)\n",
    "        backward_sequence = predict_sequence(rnn_builder[1], b_in)\n",
    "        return [\n",
    "            dy.concatenate([s1, s2])\n",
    "            for s1, s2 in zip(forward_sequence, backward_sequence)\n",
    "        ]\n",
    "    elif model.opt.encoder_dir == \"single\":\n",
    "        f_in = [entry for entry in seq]\n",
    "        state = rnn_builder[0].initial_state()\n",
    "        states = []\n",
    "        for entry in seq:\n",
    "            state = state.add_input(entry)\n",
    "            states.append(state.output())\n",
    "        return states\n",
    "\n",
    "\n",
    "def max_pooling(encoded_sequence):\n",
    "    values = np.array([encoding.value() for encoding in encoded_sequence])\n",
    "    min_indexes = np.argmax(values, axis=0)\n",
    "    pooled_context = dy.concatenate(\n",
    "        [encoded_sequence[row][col] for col, row in enumerate(min_indexes)]\n",
    "    )\n",
    "    return pooled_context\n",
    "\n",
    "\n",
    "def min_pooling(encoded_sequence):\n",
    "    values = np.array([encoding.value() for encoding in encoded_sequence])\n",
    "    min_indexes = np.argmin(values, axis=0)\n",
    "    pooled_context = dy.concatenate(\n",
    "        [encoded_sequence[row][col] for col, row in enumerate(min_indexes)]\n",
    "    )\n",
    "    return pooled_context\n",
    "\n",
    "\n",
    "def average_pooling(encoded_sequence):\n",
    "    averages = []\n",
    "    for col in range(encoded_sequence[0].dim()[0][0]):\n",
    "        avg = []\n",
    "        for row in range(len(encoded_sequence)):\n",
    "            avg.append(encoded_sequence[row][col])\n",
    "        averages.append(dy.average(avg))\n",
    "    return dy.concatenate(averages)\n",
    "\n",
    "\n",
    "def train_item(args, model, sentence):\n",
    "    loss = None\n",
    "    seq = [\n",
    "        model.wlookup[int(model.w2i.get(entry, 0))]\n",
    "        for entry in sentence.preprocessed_sentence\n",
    "    ]\n",
    "    if len(seq) > 0:\n",
    "        encoded_sequence = encode_sequence(model, seq, model.sentence_rnn)\n",
    "        global_max = max_pooling(encoded_sequence)\n",
    "        global_min = average_pooling(encoded_sequence)\n",
    "        if len(encoded_sequence) > 0:\n",
    "            att_mlp_outputs = []\n",
    "            for e in encoded_sequence:\n",
    "                mlp_out = (model.attention_w * e) + model.attention_b\n",
    "                att_mlp_outputs.append(mlp_out)\n",
    "\n",
    "            lst = []\n",
    "            for o in att_mlp_outputs:\n",
    "                lst.append(dy.exp(dy.sum_elems(dy.cmult(o, model.att_context))))\n",
    "\n",
    "            sum_all = dy.esum(lst)\n",
    "\n",
    "            probs = [dy.cdiv(e, sum_all) for e in lst]\n",
    "            att_context = dy.esum(\n",
    "                [dy.cmult(p, h) for p, h in zip(probs, encoded_sequence)]\n",
    "            )\n",
    "            context = dy.concatenate([att_context, global_max, global_min])\n",
    "            #context = dy.concatenate([att_context])\n",
    "            y_pred = dy.logistic((model.mlp_w * context) + model.mlp_b)\n",
    "\n",
    "            if sentence.permissions[args.permission_type]:\n",
    "                loss = dy.binary_log_loss(y_pred, dy.scalarInput(1))\n",
    "            else:\n",
    "                loss = dy.binary_log_loss(y_pred, dy.scalarInput(0))\n",
    "\n",
    "            loss.backward()\n",
    "            model.trainer.update()\n",
    "            loss_val = loss.scalar_value()\n",
    "            dy.renew_cg()\n",
    "            return loss_val\n",
    "    return 0\n",
    "\n",
    "\n",
    "def test_item(model, sentence):\n",
    "    seq = [\n",
    "        model.wlookup[int(model.w2i.get(entry, 0))]\n",
    "        for entry in sentence.preprocessed_sentence\n",
    "    ]\n",
    "    if len(seq) > 0:\n",
    "        encoded_sequence = encode_sequence(model, seq, model.sentence_rnn)\n",
    "        global_max = max_pooling(encoded_sequence)\n",
    "        global_min = average_pooling(encoded_sequence)\n",
    "        if len(encoded_sequence) > 0:\n",
    "            att_mlp_outputs = []\n",
    "            for e in encoded_sequence:\n",
    "                mlp_out = (model.attention_w * e) + model.attention_b\n",
    "                att_mlp_outputs.append(mlp_out)\n",
    "\n",
    "            lst = []\n",
    "            for o in att_mlp_outputs:\n",
    "                lst.append(dy.exp(dy.sum_elems(dy.cmult(o, model.att_context))))\n",
    "\n",
    "            sum_all = dy.esum(lst)\n",
    "\n",
    "            probs = [dy.cdiv(e, sum_all) for e in lst]\n",
    "            att_context = dy.esum(\n",
    "                [dy.cmult(p, h) for p, h in zip(probs, encoded_sequence)]\n",
    "            )\n",
    "            context = dy.concatenate([att_context, global_max, global_min])\n",
    "            #context = dy.concatenate([att_context])\n",
    "            y_pred = dy.logistic((model.mlp_w * context) + model.mlp_b)\n",
    "            sentence.prediction_result = y_pred.scalar_value()\n",
    "            dy.renew_cg()\n",
    "            return sentence.prediction_result\n",
    "    return 0\n",
    "\n",
    "def show_attention_weights(model, sentence):\n",
    "    seq = [\n",
    "        model.wlookup[int(model.w2i.get(entry, 0))]\n",
    "        for entry in sentence.preprocessed_sentence\n",
    "    ]\n",
    "    if len(seq) > 0:\n",
    "        encoded_sequence = encode_sequence(model, seq, model.sentence_rnn)\n",
    "        if len(encoded_sequence) > 0:\n",
    "            att_mlp_outputs = []\n",
    "            for e in encoded_sequence:\n",
    "                mlp_out = (model.attention_w * e) + model.attention_b\n",
    "                att_mlp_outputs.append(mlp_out)\n",
    "\n",
    "            lst = []\n",
    "            for o in att_mlp_outputs:\n",
    "                lst.append(dy.exp(dy.sum_elems(dy.cmult(o, model.att_context))))\n",
    "\n",
    "            sum_all = dy.esum(lst)\n",
    "            probs = [dy.cdiv(e, sum_all).scalar_value() for e in lst]\n",
    "            return probs\n",
    "\n",
    "\n",
    "def train_all(args, model, data):\n",
    "    write_file(args.outdir, \"Training...\")\n",
    "    losses = []\n",
    "    for index, sentence in enumerate(data.train_entries):\n",
    "        loss = train_item(args, model, sentence)\n",
    "        if index != 0:\n",
    "            if index % model.opt.print_every == 0:\n",
    "                write_file(\n",
    "                    args.outdir,\n",
    "                    \"Index {} Loss {}\".format(\n",
    "                        index, np.mean(losses[index - model.opt.print_every :])\n",
    "                    ),\n",
    "                )\n",
    "        losses.append(loss)\n",
    "\n",
    "\n",
    "def test_all(args, model, data):\n",
    "    def pr_roc_auc(predictions, gold):\n",
    "        y_true = np.array(gold)\n",
    "        y_scores = np.array(predictions)\n",
    "        roc_auc = roc_auc_score(y_true, y_scores)\n",
    "        pr_auc = average_precision_score(y_true, y_scores)\n",
    "        return roc_auc, pr_auc\n",
    "\n",
    "    write_file(args.outdir, \"Predicting..\")\n",
    "\n",
    "    predictions, gold = [], []\n",
    "    for index, sentence in enumerate(data.test_entries):\n",
    "        pred = test_item(model, sentence)\n",
    "        predictions.append(pred)\n",
    "        gold.append(sentence.permissions[args.permission_type])\n",
    "    return pr_roc_auc(predictions, gold)\n",
    "\n",
    "\n",
    "def kfold_validation(args, data):\n",
    "    data.entries = np.array(data.entries)\n",
    "    random.shuffle(data.entries)\n",
    "\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    roc_l, pr_l = [], []\n",
    "    for foldid, (train, test) in enumerate(kfold.split(data.entries)):\n",
    "        write_file(args.outdir, \"Fold {}\".format(foldid + 1))\n",
    "\n",
    "        model = Model(data, args)\n",
    "        data.train_entries = data.entries[train]\n",
    "        data.test_entries = data.entries[test]\n",
    "        max_roc_auc, max_pr_auc = 0, 0\n",
    "        for epoch in range(args.num_epoch):\n",
    "            train_all(args, model, data)\n",
    "            roc_auc, pr_auc = test_all(args, model, data)\n",
    "            if pr_auc > max_pr_auc:\n",
    "                max_pr_auc = pr_auc\n",
    "                max_roc_auc = roc_auc\n",
    "            write_file(\n",
    "                args.outdir, \"Epoch {} ROC {}  PR {}\".format(epoch + 1, roc_auc, pr_auc)\n",
    "            )\n",
    "        model.save()\n",
    "        write_file(args.outdir, \"ROC {} PR {}\".format(max_roc_auc, max_pr_auc))\n",
    "        roc_l.append(max_roc_auc)\n",
    "        pr_l.append(max_pr_auc)\n",
    "    write_file(\n",
    "        args.outdir, \"Summary : ROC {} PR {}\".format(np.mean(roc_l), np.mean(pr_l))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    permission_type = \"READ_CONTACTS\"\n",
    "    saved_data = \"/Users/huseyinalecakir/huseyin/Work/Security/datasets/saved-parameters/saved-data/ac-net/embeddings-sentences-w2i.pickle\"\n",
    "    outdir = \"output.txt\"\n",
    "    stemmer = \"porter\"\n",
    "    embedding_size = 300\n",
    "    hidden_size = 128\n",
    "    attention_size = 128\n",
    "    output_size = 1\n",
    "    print_every = 1000\n",
    "    encoder_dir = \"bidirectional\"\n",
    "    encoder_type = \"gru\"\n",
    "    num_epoch = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"data.entries = np.array(data.entries)\n",
    "random.shuffle(data.entries)\n",
    "from sklearn.model_selection import train_test_split\n",
    "data.train_entries, data.test_entries = train_test_split(data.entries, test_size=0.10, random_state=5)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train_test(infile):\n",
    "    with open(infile, \"rb\") as target:\n",
    "        data.entries, data.train_entries, data.test_entries = pickle.load(target)\n",
    "\n",
    "def save_train_test(infile):\n",
    "    with open(infile, \"wb\") as target:\n",
    "        pickle.dump([data.entries, data.train_entries, data.test_entries], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_train_test(\"porter_train_test.pickle\")\n",
    "load_train_test(\"porter_train_test.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get the document ids of saved dataset.\"\"\"\n",
    "test_document_ids = set()\n",
    "for document in data.test_entries:\n",
    "    test_document_ids.add(document.app_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "data = Data()\n",
    "data.load(args.saved_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get the related sentences from document id list\"\"\"\n",
    "data.test_entries = []\n",
    "data.train_entries = []\n",
    "for entry in data.entries:\n",
    "    if entry.app_id in test_document_ids:\n",
    "        data.test_entries.append(entry)\n",
    "    else:\n",
    "        data.train_entries.append(entry)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976828874588 0.684400123991\n"
     ]
    }
   ],
   "source": [
    "model = Model(data, args)\n",
    "train_all(args, model, data)\n",
    "roc_auc, pr_auc = test_all(args, model, data)\n",
    "print(roc_auc, pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"for entry in data.test_entries:\n",
    "    if type(entry.prediction_result) != float:\n",
    "        entry.prediction_result = 0\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:58 - FN:39 - TN:2366 - FP:29\n",
      "Precision:0.6666666666666666 - Recall:0.5979381443298969\n",
      "Accuracy:0.9727126805778491\n",
      "F-measuse:0.6304347826086957\n"
     ]
    }
   ],
   "source": [
    "positives = [entry for entry in data.test_entries if entry.permissions[\"READ_CONTACTS\"]==1]\n",
    "negatives = [entry for entry in data.test_entries if entry.permissions[\"READ_CONTACTS\"]==0]\n",
    "\n",
    "sorted_positives = sorted(positives, key=lambda x: x.prediction_result, reverse=True)\n",
    "sorted_negatives = sorted(negatives, key=lambda x: x.prediction_result, reverse=True)\n",
    "threshold = 0.50\n",
    "TP = sum([1 for entry in sorted_positives if entry.prediction_result >= threshold])\n",
    "FN = sum([1 for entry in sorted_positives if entry.prediction_result < threshold])\n",
    "TN = sum([1 for entry in sorted_negatives if entry.prediction_result < threshold])\n",
    "FP = sum([1 for entry in sorted_negatives if entry.prediction_result >= threshold])\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "acc = (TN+TP)/(TN+FP+TP+FN)\n",
    "fmeasure = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "print(\"TP:{} - FN:{} - TN:{} - FP:{}\".format(TP, FN, TN, FP))\n",
    "print(\"Precision:{} - Recall:{}\".format(precision, recall))\n",
    "print(\"Accuracy:{}\".format(acc))\n",
    "print(\"F-measuse:{}\".format(fmeasure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"statement_sentences.txt\", \"w\") as target:\n",
    "    for idx, entry in enumerate(sorted_negatives):\n",
    "        if entry.prediction_result > 0:\n",
    "            target.write(\"{}\\t{}\\t{}\\n\".format(idx+1, entry.sentence, entry.prediction_result))\n",
    "            target.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"permission_sentences.txt\", \"w\") as target:\n",
    "    for idx, entry in enumerate(sorted_positives[::-1]):\n",
    "        target.write(\"{}::{}::{}\\n\".format(idx+1, entry.sentence, entry.prediction_result))\n",
    "        target.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Group test sentences by app_id\"\"\"\n",
    "app_sentences_max_prediction = {}\n",
    "for entry in data.test_entries:\n",
    "    if entry.app_id not in app_sentences_max_prediction:\n",
    "        app_sentences_max_prediction[entry.app_id] = 0\n",
    "    if entry.prediction_result > app_sentences_max_prediction[entry.app_id]:\n",
    "        app_sentences_max_prediction[entry.app_id] = entry.prediction_result\n",
    "        \n",
    "app_sentences_gold = {}\n",
    "for entry in data.test_entries:\n",
    "    if entry.app_id not in app_sentences_gold:\n",
    "        app_sentences_gold[entry.app_id] = entry.permissions[\"READ_CONTACTS\"]\n",
    "    elif entry.permissions[\"READ_CONTACTS\"] == 1:\n",
    "        app_sentences_gold[entry.app_id] = entry.permissions[\"READ_CONTACTS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.2\n",
      "TP:34 - FN:7 - TN:83 - FP:18\n",
      "Precision:0.6538461538461539 - Recall:0.8292682926829268\n",
      "Accuracy:0.823943661971831\n",
      "F-measuse:0.7311827956989247\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.20\n",
    "\n",
    "TP = sum([1 for key in app_sentences_max_prediction if app_sentences_gold[key] == 1 and app_sentences_max_prediction[key] >= threshold])\n",
    "FN = sum([1 for key in app_sentences_max_prediction if app_sentences_gold[key] == 1 and app_sentences_max_prediction[key] < threshold])\n",
    "TN = sum([1 for key in app_sentences_max_prediction if app_sentences_gold[key] == 0 and app_sentences_max_prediction[key] < threshold])\n",
    "FP = sum([1 for key in app_sentences_max_prediction if app_sentences_gold[key] == 0 and app_sentences_max_prediction[key] >= threshold])\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "acc = (TN+TP)/(TN+FP+TP+FN)\n",
    "fmeasure = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Threshold {}\".format(threshold))\n",
    "print(\"TP:{} - FN:{} - TN:{} - FP:{}\".format(TP, FN, TN, FP))\n",
    "print(\"Precision:{} - Recall:{}\".format(precision, recall))\n",
    "print(\"Accuracy:{}\".format(acc))\n",
    "print(\"F-measuse:{}\".format(fmeasure))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
