{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import SentenceReport, DocumentReport\n",
    "from utils.nlp_utils import NLPUtils\n",
    "from utils.io_utils import IOUtils\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentences(infile, permission, stemmer, embeddings):\n",
    "    print(\"Loading row {} \".format(infile))\n",
    "    tagged_train_file = pd.read_csv(infile)\n",
    "    sentences = []\n",
    "    \n",
    "    app_id = None\n",
    "    for idx, row in tagged_train_file.iterrows():\n",
    "        sentence_id = str(row[\"app_id\"])\n",
    "        sentence = row[\"sentence\"]\n",
    "        if sentence_id.startswith(\"##\"):\n",
    "            app_id = sentence_id\n",
    "        if not (sentence.startswith(\"##\") or sentence.startswith(\"Description Tag\") or sentence.startswith(\"CATEGORY\")):\n",
    "            try:\n",
    "                if int(row[permission]) == 1 or int(row[permission]) == 0: #eliminate different tags other than zero and one       \n",
    "                    sentence_report = SentenceReport(app_id, sentence)\n",
    "                    sentence_report.permissions[permission] = int(row[permission])\n",
    "                    preprocessed = NLPUtils.preprocess_sentence(sentence, stemmer)\n",
    "                    sentence_report.preprocessed_sentence = [word for word in preprocessed if word in embeddings]\n",
    "                    if sentence_report.preprocessed_sentence != []:\n",
    "                        sentences.append(sentence_report)\n",
    "                else:\n",
    "                    pass\n",
    "                    # Pass tags other than zero and one \n",
    "            except:\n",
    "                pass # sentences with no tag\n",
    "    print(\"Loading completed\")\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(infile, permission, stemmer, embeddings):\n",
    "    print(\"Loading row {} \".format(infile))\n",
    "    tagged_train_file = pd.read_csv(infile)\n",
    "    documents = []\n",
    "    \n",
    "    app_id = None\n",
    "    for idx, row in tagged_train_file.iterrows():\n",
    "        sentence_id = str(row[\"app_id\"])\n",
    "        sentence = row[\"sentence\"]\n",
    "        if sentence_id.startswith(\"##\"):\n",
    "            app_id = sentence_id\n",
    "            documents.append(DocumentReport(app_id))\n",
    "            documents[-1].permissions[permission] = 0\n",
    "        if not (sentence.startswith(\"##\") or sentence.startswith(\"Description Tag\") or sentence.startswith(\"CATEGORY\")):\n",
    "            if not (sentence.startswith(\"##\") or sentence.startswith(\"Description Tag\") or sentence.startswith(\"CATEGORY\")):\n",
    "                try:\n",
    "                    if int(row[permission]) == 1 or int(row[permission]) == 0: #eliminate different tags other than zero and one       \n",
    "                        if row[permission] == 1:\n",
    "                            documents[-1].permissions[permission] = 1\n",
    "                        documents[-1].sentences.append(sentence)\n",
    "                        preprocessed = NLPUtils.preprocess_sentence(sentence, stemmer)\n",
    "                        filtered = [word for word in preprocessed if word in embeddings]\n",
    "                        documents[-1].preprocessed_sentences.append(filtered)\n",
    "                    else:\n",
    "                        pass\n",
    "                        # Pass tags other than zero and one \n",
    "                except:\n",
    "                    pass # sentences with no tag\n",
    "    print(\"Loading completed\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(infile, permission, stemmer, embeddings):\n",
    "    print(\"Loading row {} \".format(infile))\n",
    "    tagged_train_file = pd.read_csv(infile)\n",
    "    w2i = {}\n",
    "    for idx, row in tagged_train_file.iterrows():\n",
    "        sentence = row[\"sentence\"]\n",
    "\n",
    "        if not (sentence.startswith(\"##\") or sentence.startswith(\"Description Tag\") or sentence.startswith(\"CATEGORY\")):\n",
    "            try:\n",
    "                if int(row[permission]) == 1 or int(row[permission]) == 0: #eliminate different tags other than zero and one       \n",
    "                    preprocessed = NLPUtils.preprocess_sentence(sentence, stemmer)\n",
    "                    filtered = [word for word in preprocessed if word in embeddings]\n",
    "                    for token in filtered:\n",
    "                        if token not in w2i:\n",
    "                            w2i[token] = len(w2i)\n",
    "                else:\n",
    "                    pass\n",
    "                    # Pass tags other than zero and one \n",
    "            except:\n",
    "                pass # sentences with no tag\n",
    "    print(\"Loading completed\")\n",
    "    return w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_vocab_embeddings(w2i, embeddings):\n",
    "    subset = {}\n",
    "    for key in w2i:\n",
    "        subset[key] = embeddings[key]\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sentence_based_dataset(infile, permission, embeddings, stemmer, outfile):\n",
    "    sentences = load_sentences(infile, permission, stemmer, embeddings)\n",
    "    w2i = vocab(infile, permission, stemmer, embeddings)\n",
    "    subset_embeddings = filtered_vocab_embeddings(w2i, embeddings)\n",
    "    with open(outfile, \"wb\") as target:\n",
    "        pickle.dump([subset_embeddings, sentences, w2i], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_document_based_dataset(infile, permission, embeddings, stemmer, outfile):\n",
    "    documents = load_documents(infile, permission, stemmer, embeddings)\n",
    "    w2i = vocab(infile, permission, stemmer, embeddings)\n",
    "    subset_embeddings = filtered_vocab_embeddings(w2i, embeddings)\n",
    "    with open(outfile, \"wb\") as target:\n",
    "        pickle.dump([subset_embeddings, documents, w2i], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = \"porter\"\n",
    "embeddings_file = os.path.join(os.environ[\"SECURITY_DATASETS\"], \"embeddings/own-embeddings/scraped_with_porter_stemming_300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, embeddings_dim = IOUtils.load_embeddings_file(embeddings_file, \"word2vec\", lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading row STORAGE.csv \n",
      "Loading completed\n",
      "Loading row STORAGE.csv \n",
      "Loading completed\n",
      "Loading row RECORD_AUDIO.csv \n",
      "Loading completed\n",
      "Loading row RECORD_AUDIO.csv \n",
      "Loading completed\n",
      "Loading row READ_CONTACTS.csv \n",
      "Loading completed\n",
      "Loading row READ_CONTACTS.csv \n",
      "Loading completed\n"
     ]
    }
   ],
   "source": [
    "#create sentence based embeddings\n",
    "permission = \"STORAGE\"\n",
    "infile = \"{}.csv\".format(permission)\n",
    "outfile = \"{}-embeddings-sentences-w2i.pickle\".format(permission)\n",
    "save_sentence_based_dataset(infile, permission, embeddings, stemmer, outfile)\n",
    "\n",
    "permission = \"RECORD_AUDIO\"\n",
    "infile = \"{}.csv\".format(permission)\n",
    "outfile = \"{}-embeddings-sentences-w2i.pickle\".format(permission)\n",
    "save_sentence_based_dataset(infile, permission, embeddings, stemmer, outfile)\n",
    "\n",
    "permission = \"READ_CONTACTS\"\n",
    "infile = \"{}.csv\".format(permission)\n",
    "outfile = \"{}-embeddings-sentences-w2i.pickle\".format(permission)\n",
    "save_sentence_based_dataset(infile, permission, embeddings, stemmer, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading row STORAGE.csv \n",
      "Loading completed\n",
      "Loading row STORAGE.csv \n",
      "Loading completed\n",
      "Loading row RECORD_AUDIO.csv \n",
      "Loading completed\n",
      "Loading row RECORD_AUDIO.csv \n",
      "Loading completed\n",
      "Loading row READ_CONTACTS.csv \n",
      "Loading completed\n",
      "Loading row READ_CONTACTS.csv \n",
      "Loading completed\n"
     ]
    }
   ],
   "source": [
    "#create document based embeddings\n",
    "permission = \"STORAGE\"\n",
    "infile = \"{}.csv\".format(permission)\n",
    "outfile = \"{}-embeddings-documents-w2i.pickle\".format(permission)\n",
    "save_document_based_dataset(infile, permission, embeddings, stemmer, outfile)\n",
    "\n",
    "permission = \"RECORD_AUDIO\"\n",
    "infile = \"{}.csv\".format(permission)\n",
    "outfile = \"{}-embeddings-documents-w2i.pickle\".format(permission)\n",
    "save_document_based_dataset(infile, permission, embeddings, stemmer, outfile)\n",
    "\n",
    "permission = \"READ_CONTACTS\"\n",
    "infile = \"{}.csv\".format(permission)\n",
    "outfile = \"{}-embeddings-documents-w2i.pickle\".format(permission)\n",
    "save_document_based_dataset(infile, permission, embeddings, stemmer, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasttext embeddings version\n",
    "embeddings_file = os.path.join(os.environ[\"SECURITY_DATASETS\"], \"embeddings/cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, embeddings_dim = IOUtils.load_embeddings_file(embeddings_file, \"fasttext\", lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading row STORAGE.csv \n",
      "Loading completed\n",
      "Loading row STORAGE.csv \n",
      "Loading completed\n",
      "Loading row RECORD_AUDIO.csv \n",
      "Loading completed\n",
      "Loading row RECORD_AUDIO.csv \n",
      "Loading completed\n",
      "Loading row READ_CONTACTS.csv \n",
      "Loading completed\n",
      "Loading row READ_CONTACTS.csv \n",
      "Loading completed\n"
     ]
    }
   ],
   "source": [
    "#create sentence based embeddings\n",
    "permission = \"STORAGE\"\n",
    "infile = \"{}.csv\".format(permission)\n",
    "outfile = \"{}-fasttext-embeddings-sentences-w2i.pickle\".format(permission)\n",
    "save_sentence_based_dataset(infile, permission, embeddings, stemmer, outfile)\n",
    "\n",
    "permission = \"RECORD_AUDIO\"\n",
    "infile = \"{}.csv\".format(permission)\n",
    "outfile = \"{}-fasttext-embeddings-sentences-w2i.pickle\".format(permission)\n",
    "save_sentence_based_dataset(infile, permission, embeddings, stemmer, outfile)\n",
    "\n",
    "permission = \"READ_CONTACTS\"\n",
    "infile = \"{}.csv\".format(permission)\n",
    "outfile = \"{}-fasttext-embeddings-sentences-w2i.pickle\".format(permission)\n",
    "save_sentence_based_dataset(infile, permission, embeddings, stemmer, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
